{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading training database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json, os, warnings, re\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import glob\n",
    "data_raw= pd.read_json(\"./1.TrainingData/all.json\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Exclude</th>\n",
       "      <th>appId</th>\n",
       "      <th>comment</th>\n",
       "      <th>dataSource</th>\n",
       "      <th>date</th>\n",
       "      <th>fee</th>\n",
       "      <th>future</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>lemmatized_comment</th>\n",
       "      <th>...</th>\n",
       "      <th>reviewId</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>sentiScore</th>\n",
       "      <th>sentiScore_neg</th>\n",
       "      <th>sentiScore_pos</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>stopwords_removal</th>\n",
       "      <th>stopwords_removal_lemmatization</th>\n",
       "      <th>stopwords_removal_nltk</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>Besides the occasional crash, this is an amazi...</td>\n",
       "      <td>RE2014_app_and_play_store_apps</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>264</td>\n",
       "      <td>Bug</td>\n",
       "      <td>besides the occasional crash, this be an amaze...</td>\n",
       "      <td>...</td>\n",
       "      <td>10946</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>besid the occa crash, thi is an amaz produc wi...</td>\n",
       "      <td>besides occasional crash, this amazing product...</td>\n",
       "      <td>besides occasional crash, this amaze product w...</td>\n",
       "      <td>besides occasional crash, amazing product tons...</td>\n",
       "      <td>Almost perfect</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Exclude appId                                            comment  \\\n",
       "0     NaN  None  Besides the occasional crash, this is an amazi...   \n",
       "\n",
       "                       dataSource  date   fee  future   id label  \\\n",
       "0  RE2014_app_and_play_store_apps  None  None       0  264   Bug   \n",
       "\n",
       "                                  lemmatized_comment  ...  reviewId  reviewer  \\\n",
       "0  besides the occasional crash, this be an amaze...  ...     10946      None   \n",
       "\n",
       "   sentiScore  sentiScore_neg  sentiScore_pos  \\\n",
       "0           3              -1               3   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  besid the occa crash, thi is an amaz produc wi...   \n",
       "\n",
       "                                   stopwords_removal  \\\n",
       "0  besides occasional crash, this amazing product...   \n",
       "\n",
       "                     stopwords_removal_lemmatization  \\\n",
       "0  besides occasional crash, this amaze product w...   \n",
       "\n",
       "                              stopwords_removal_nltk           title  \n",
       "0  besides occasional crash, amazing product tons...  Almost perfect  \n",
       "\n",
       "[1 rows x 25 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw[0:1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata_noRating=data_raw[data_raw[\"label\"]!=\"Rating\"]\n",
    "traindata_Rating=data_raw[data_raw[\"label\"]==\"Rating\"]\n",
    "traindata_Rating_sample=traindata_Rating.sample(n=1000, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rating            1000\n",
       "UserExperience     607\n",
       "Bug                370\n",
       "Feature            252\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData = pd.concat([traindata_noRating, traindata_Rating_sample], axis=0)\n",
    "trainData.label.value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.  STARTING TO TRAIN THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def measuretool(df,classvalue):   \n",
    "    df[\"validate\"]=df[\"response\"]==df[\"predict\"]\n",
    "    a_value=sum(df[df[\"predict\"]==classvalue][\"validate\"])\n",
    "    ac_value=len(df[df[\"predict\"]==classvalue])\n",
    "    ab_value=len(df[df[\"response\"]==classvalue])\n",
    "    Precision_value=a_value/ac_value\n",
    "    Recall_value=a_value/ab_value\n",
    "    F1_value=2*Precision_value*Recall_value/(Precision_value+Recall_value)\n",
    "    return [Precision_value,Recall_value,F1_value]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. BOW + Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training predictors\n",
    "trainText=trainData.comment\n",
    "vect = CountVectorizer(ngram_range=(2, 2))\n",
    "X_train_BOW_Bigram = vect.fit_transform(trainText).toarray()\n",
    "Y_train=trainData.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training model\n",
    "classifier_11 = GaussianNB()\n",
    "classifier_11.fit(X_train_BOW_Bigram,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9724517906336089, 0.9540540540540541, 0.9631650750341064]\n",
      "[1.0, 0.7677100494233937, 0.8685927306616962]\n",
      "[0.5727272727272728, 1.0, 0.7283236994219653]\n",
      "[0.88125, 0.846, 0.863265306122449]\n"
     ]
    }
   ],
   "source": [
    "# Get predict value on the training dataset\n",
    "Y_train_pred_11 = classifier_11.predict(X_train_BOW_Bigram)\n",
    "# Accuracy \n",
    "accuracy = accuracy_score(Y_train, Y_train_pred_11)\n",
    "accuracy\n",
    "# Combince result\n",
    "df_11 = pd.DataFrame({'response':Y_train, 'predict':Y_train_pred_11})\n",
    "print(measuretool(df_11,\"Bug\"))\n",
    "print(measuretool(df_11,\"UserExperience\"))\n",
    "print(measuretool(df_11,\"Feature\"))\n",
    "print(measuretool(df_11,\"Rating\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Vectorizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "16\n",
      "8\n",
      "14\n",
      "55\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer(max_features=1000)\n",
    "trainingText_stopwords_removal_nlt = vect.fit_transform(trainingText).toarray()\n",
    "for i in range(5):\n",
    "    print(sum(trainingText_stopwords_removal_nlt[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25602817664589544"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes \n",
    "\n",
    "\n",
    "\n",
    "# Predict Class\n",
    "y_pred = classifier.predict(trainingText_stopwords_removal_nlt)\n",
    "\n",
    "# Accuracy \n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(trainingResponse, y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. STARTING TESTING MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Loading Testing Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "Testingdata= pd.read_csv(\"./2.TestingData/Testing300Sample_completed.csv\") \n",
    "X_testing=Testingdata[\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Preprocessing the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "\n",
    "testingText = testingData.text\n",
    "\n",
    "#Preprocessing the data: Remove none alphabetic characters/Make the word lower case/Remove the stop words\n",
    "\n",
    "def mutlti_func(x):       \n",
    "    text= word_tokenize(str(re.sub('[^A-Za-z]', ' ', x)).lower())\n",
    "    for word in text:\n",
    "        if word in stopwords.words('english'):\n",
    "            text.remove(word)\n",
    "    return text\n",
    "\n",
    "\n",
    "testingText=testingText.apply(mutlti_func)\n",
    "testingText.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "\n",
    "# Stemming / Spelling \n",
    "spell = SpellChecker()\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stem_spell_fuc(x):\n",
    "    for i in range(len(x)):\n",
    "        #x[i] = stemmer.stem(spell.correction(x[i]))\n",
    "        x[i] = stemmer.stem(x[i])\n",
    "    return x\n",
    "\n",
    "testingText=testingText.apply(stem_spell_fuc)\n",
    "testingText.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_fuc(x):\n",
    "    x = \" \".join(x)\n",
    "    return x\n",
    "\n",
    "testingText=testingText.apply(join_fuc)\n",
    "testingText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Running testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict Class\n",
    "y_testing_pred = classifier.predict(testingText)\n",
    "y_testing_pred.head(20)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

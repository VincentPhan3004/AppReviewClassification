{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading training database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json, os, warnings, re\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import glob\n",
    "data_raw= pd.read_json(\"./1.TrainingData/all.json\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Exclude</th>\n",
       "      <th>appId</th>\n",
       "      <th>comment</th>\n",
       "      <th>dataSource</th>\n",
       "      <th>date</th>\n",
       "      <th>fee</th>\n",
       "      <th>future</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>lemmatized_comment</th>\n",
       "      <th>...</th>\n",
       "      <th>reviewId</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>sentiScore</th>\n",
       "      <th>sentiScore_neg</th>\n",
       "      <th>sentiScore_pos</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>stopwords_removal</th>\n",
       "      <th>stopwords_removal_lemmatization</th>\n",
       "      <th>stopwords_removal_nltk</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>Besides the occasional crash, this is an amazi...</td>\n",
       "      <td>RE2014_app_and_play_store_apps</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>264</td>\n",
       "      <td>Bug</td>\n",
       "      <td>besides the occasional crash, this be an amaze...</td>\n",
       "      <td>...</td>\n",
       "      <td>10946</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>besid the occa crash, thi is an amaz produc wi...</td>\n",
       "      <td>besides occasional crash, this amazing product...</td>\n",
       "      <td>besides occasional crash, this amaze product w...</td>\n",
       "      <td>besides occasional crash, amazing product tons...</td>\n",
       "      <td>Almost perfect</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Exclude appId                                            comment  \\\n",
       "0     NaN  None  Besides the occasional crash, this is an amazi...   \n",
       "\n",
       "                       dataSource  date   fee  future   id label  \\\n",
       "0  RE2014_app_and_play_store_apps  None  None       0  264   Bug   \n",
       "\n",
       "                                  lemmatized_comment  ...  reviewId  reviewer  \\\n",
       "0  besides the occasional crash, this be an amaze...  ...     10946      None   \n",
       "\n",
       "   sentiScore  sentiScore_neg  sentiScore_pos  \\\n",
       "0           3              -1               3   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  besid the occa crash, thi is an amaz produc wi...   \n",
       "\n",
       "                                   stopwords_removal  \\\n",
       "0  besides occasional crash, this amazing product...   \n",
       "\n",
       "                     stopwords_removal_lemmatization  \\\n",
       "0  besides occasional crash, this amaze product w...   \n",
       "\n",
       "                              stopwords_removal_nltk           title  \n",
       "0  besides occasional crash, amazing product tons...  Almost perfect  \n",
       "\n",
       "[1 rows x 25 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw[0:1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata_noRating=data_raw[data_raw[\"label\"]!=\"Rating\"]\n",
    "traindata_Rating=data_raw[data_raw[\"label\"]==\"Rating\"]\n",
    "traindata_Rating_sample=traindata_Rating.sample(n=1000, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rating            1000\n",
       "UserExperience     607\n",
       "Bug                370\n",
       "Feature            252\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData = pd.concat([traindata_noRating, traindata_Rating_sample], axis=0)\n",
    "trainData.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.  STARTING TO TRAIN THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def measuretool(df,classvalue):   \n",
    "    df[\"validate\"]=df[\"response\"]==df[\"predict\"]\n",
    "    a_value=sum(df[df[\"predict\"]==classvalue][\"validate\"])\n",
    "    ac_value=len(df[df[\"predict\"]==classvalue])\n",
    "    ab_value=len(df[df[\"response\"]==classvalue])\n",
    "    Precision_value=a_value/ac_value\n",
    "    Recall_value=a_value/ab_value\n",
    "    F1_value=2*Precision_value*Recall_value/(Precision_value+Recall_value)\n",
    "    return pd.DataFrame({'Precision':[Precision_value], 'Recall':[Recall_value], 'F1_value' :[F1_value]})\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. BOW + Bigram - Stopwords_Removal + Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training predictors\n",
    "trainText=trainData.stopwords_removal_lemmatization\n",
    "vect_11 = CountVectorizer(ngram_range=(2, 2))\n",
    "X_train = vect_11.fit_transform(trainText).toarray()\n",
    "Y_train = trainData.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training model\n",
    "classifier_11 = GaussianNB()\n",
    "classifier_11.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Precision    Recall  F1_value\n",
      "0   0.972452  0.954054  0.963165\n",
      "   Precision   Recall  F1_value\n",
      "0        1.0  0.76771  0.868593\n",
      "   Precision  Recall  F1_value\n",
      "0   0.581986     1.0  0.735766\n",
      "   Precision  Recall  F1_value\n",
      "0   0.881075   0.852  0.866294\n"
     ]
    }
   ],
   "source": [
    "# Get predict value on the training dataset\n",
    "Y_train_pred_11 = classifier_11.predict(X_train)\n",
    "# Combince result\n",
    "df_11 = pd.DataFrame({'response':Y_train, 'predict':Y_train_pred_11})\n",
    "print(measuretool(df_11,\"Bug\"))\n",
    "print(measuretool(df_11,\"UserExperience\"))\n",
    "print(measuretool(df_11,\"Feature\"))\n",
    "print(measuretool(df_11,\"Rating\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. STARTING TESTING MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Loading Testing Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Testingdata= pd.read_csv(\"./2.TestingData/Testing300Sample_completed.csv\") \n",
    "len(Testingdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Preprocessing the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "# joing string\n",
    "def join_func(x):\n",
    "    x = \" \".join(x)\n",
    "    return x\n",
    "\n",
    "#Preprocessing the data: Remove none alphabetic characters/Make the word lower case\n",
    "def cleantext(x):       \n",
    "    x = re.sub('[^A-Za-z]', ' ', x)\n",
    "    x = str(x).lower()\n",
    "    return x\n",
    "\n",
    "#Remove the stop words\n",
    "def stopword(x):\n",
    "    x= word_tokenize(x)\n",
    "    for word in x:\n",
    "        if word in stopwords.words('english'):\n",
    "            x.remove(word)\n",
    "    return join_func(x)\n",
    "    \n",
    "#stemming\n",
    "stemmer = PorterStemmer()\n",
    "def stem_fuc(x):\n",
    "    x= word_tokenize(x)\n",
    "    for i in range(len(x)):\n",
    "        x[i] = stemmer.stem(x[i])\n",
    "    return join_func(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Test Data\n",
    "X_testing=Testingdata.text\n",
    "X_testing=X_testing.apply(cleantext)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop_word\n",
    "X_testing=X_testing.apply(stopword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stemming\n",
    "X_testing=X_testing.apply(stem_fuc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 BOW + Bigram - Stopwords_Removal + Lemmatization (testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vecotorizer BOW + Bigram for testing data\n",
    "vect11_testing = CountVectorizer(ngram_range=(2, 2),vocabulary=vect_11.vocabulary_)\n",
    "X_testing_matrix = vect11_testing.fit_transform(X_testing).toarray()\n",
    "Y_testing=Testingdata.label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predict value on the training dataset with BOW +Bigram model\n",
    "Y_testing_pred_11 = classifier_11.predict(X_testing_matrix)\n",
    "df_11_testing = pd.DataFrame({'response':Y_testing, 'predict':Y_testing_pred_11})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Precision    Recall  F1_value\n",
      "0   0.296296  0.190476  0.231884\n",
      "   Precision   Recall  F1_value\n",
      "0   0.535714  0.16129  0.247934\n",
      "   Precision    Recall  F1_value\n",
      "0   0.111702  0.567568  0.186667\n",
      "   Precision    Recall  F1_value\n",
      "0   0.368421  0.164062  0.227027\n"
     ]
    }
   ],
   "source": [
    "print(measuretool(df_11_testing,\"Bug\"))\n",
    "print(measuretool(df_11_testing,\"UserExperience\"))\n",
    "print(measuretool(df_11_testing,\"Feature\"))\n",
    "print(measuretool(df_11_testing,\"Rating\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
